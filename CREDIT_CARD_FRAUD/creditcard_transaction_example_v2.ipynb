{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"profile_manoelgadi.png\" width=100 height=100 align=\"right\">\n",
    "\n",
    "Author: Prof. Manoel Gadi\n",
    "\n",
    "Contact: mfalonso@faculty.ie.edu\n",
    "\n",
    "Teaching Web: http://mfalonso.pythonanywhere.com\n",
    "\n",
    "Last revision: 24/February/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manoe\\AppData\\Local\\Temp\\ipykernel_23452\\1226147920.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "__Objective of today's session__ - Review for the exam.\n",
    "\n",
    "* Get in touch with a real Credit Card Transaction Fraud Dataset (from Brazil). \n",
    "* Learn the concept of oversample and downsample for unbalanced data\n",
    "\n",
    "Learn, review and discuss in general and specific for unbalance data: \n",
    "* Gini\n",
    "* Population Stability Index\n",
    "* Weight of evidence and Information Value\n",
    "* Correlation - Spearman Ranking\n",
    "* Feature selection\n",
    "* Overfitting\n",
    "\n",
    "Grouping - discuss how to transform or when to drop  variables according to the type of variable:\n",
    "* primary key auto incremental (id)\n",
    "* input binary - flag 0/1 variable\n",
    "* input categorical nominal\n",
    "* input categorical ordinal\n",
    "* input numerical continuos (input float)\n",
    "* dates\n",
    "* future variables\n",
    "* Target variable\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"00_frauddetection.jpg\"  width=500 height=500 align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard_transaction_fraud_full.csv\")\n",
    "df.index = df.iloc[:,0]\n",
    "df = df.drop(df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41647, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>merchant_category_code_cat</th>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_category_code_previoustransaction_cat</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_cat</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_previoustransaction_cat</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_value_cat</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_value_previoustransaction_cat</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_entry</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creditcard_limit_cat</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_visa_mastercard_cat</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_of_creditcard_cat</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraudscore_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_person_cat</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_nacional_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numb_of_installments_cat</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactionspeed_cat</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dif_fraudscore_cat</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_limit_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TARGET</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Unnamed: 0                                         0     1     2    3     4\n",
       "merchant_category_code_cat                       9.0  22.0  22.0  9.0  15.0\n",
       "merchant_category_code_previoustransaction_cat  22.0  22.0  22.0  0.0   9.0\n",
       "zipcode_cat                                      3.0   3.0   3.0  2.0   2.0\n",
       "zipcode_previoustransaction_cat                  3.0   3.0   3.0  0.0   2.0\n",
       "transaction_value_cat                            6.0   7.0   7.0  4.0   4.0\n",
       "transaction_value_previoustransaction_cat        6.0   7.0   7.0  1.0   4.0\n",
       "pos_entry                                        2.0   2.0   2.0  2.0   2.0\n",
       "creditcard_limit_cat                             6.0   6.0   6.0  4.0   4.0\n",
       "brand_visa_mastercard_cat                        2.0   2.0   2.0  2.0   2.0\n",
       "type_of_creditcard_cat                           3.0   3.0   3.0  3.0   3.0\n",
       "fraudscore_cat                                   0.0   0.0   3.0  0.0   0.0\n",
       "type_person_cat                                  1.0   1.0   1.0  1.0   1.0\n",
       "trans_nacional_cat                               0.0   0.0   0.0  0.0   0.0\n",
       "numb_of_installments_cat                         1.0   1.0   1.0  1.0   1.0\n",
       "transactionspeed_cat                             7.0   4.0   6.0  2.0   3.0\n",
       "dif_fraudscore_cat                               1.0   4.0   5.0  3.0   3.0\n",
       "transaction_limit_cat                            0.0   0.0   0.0  0.0   0.0\n",
       "TARGET                                           0.0   0.0   1.0  0.0   0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All information has been grouped in categories:\n",
    "\n",
    "### DISCUSSION 1) How to transform or when to drop  variables based simply on the type of variable?\n",
    "\n",
    "* primary key auto incremental (id) - __drop__\n",
    "* input binary - flag 0/1 variable - __do nothing__\n",
    "* input categorical nominal - __create dummies__ (if necessary to reduce categories: apply WoE transformation followed by percentile / quantile grouping followed by dummy creation). Quantile grouping aims to reduce impact of outliers\n",
    "* input categorical ordinal - __do nothing__ (if necessary to reduce categories: __percentile/quantile grouping followed by dummy creation__)\n",
    "* input numerical continuos (input float) - __do nothing__ if necessary to reduce categories: __percentile/quantile grouping followed by dummy creation__)\n",
    "* dates - never use as dates, transform into difference of dates then apply - __percentile or quantile grouping__\n",
    "* future variables - __drop__\n",
    "* Target variable - __create the y with it, remove it from X__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FRAUD RATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03743366869162244\n"
     ]
    }
   ],
   "source": [
    "print(df['TARGET'].sum() / df['TARGET'].count()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "The dataset has been downsampled 100x (reducing non-fraud cases randomly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"06_oversampling.JPG\"  width=500 height=500 align=\"center\">\n",
    "\n",
    "__Oversampling__ is a techinique where one replicates (oversample) the minority class (fraud) in order to balance different costs for false positives and false negatives. Oversampling of minority class is recomended for small/medium dataset sizes.\n",
    "\n",
    "__Undersampling__ is a technique where one samples the majority class (non-fraud) down rate in order to balance different costs for false positives and false negatives. Undersampling the majority class is recomended for big/huge dataset sizes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Fraud Rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003887432521627116\n"
     ]
    }
   ],
   "source": [
    "print(df['TARGET'].sum() / ((df['TARGET'].count()-df['TARGET'].sum())*100+df['TARGET'].sum()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.887432521627116 basis points\n"
     ]
    }
   ],
   "source": [
    "print(10000*df['TARGET'].sum() / ((df['TARGET'].count()-df['TARGET'].sum())*100+df['TARGET'].sum()),\"basis points\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"01_haystatck.JPG\"  width=500 height=500 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"02_fraud_prevention.JPG\"  width=500 height=500 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"03_type_of_fraud.JPG\"  width=500 height=500 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy is not a good measure to use in here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"04_recall.JPG\"  width=500 height=500 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is mportant is to find the fraud. We can use recall, KS, GINI or calculate the actual cost of fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"05_cost_of_fraud.JPG\"  width=500 height=500 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this example we will use GINI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (33317, 18)\n",
      "Dataset shape: (8330, 18)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "splitter = train_test_split\n",
    "\"-----------------------\"\n",
    "\n",
    "df_train, df_test = splitter(df, test_size = 0.2, random_state = 42)\n",
    "print(\"Dataset shape: {shape}\".format(shape = df_train.shape))\n",
    "print(\"Dataset shape: {shape}\".format(shape = df_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the final variables and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_columns(df, data_types, to_ignore = list(), ignore_target = False):\n",
    "    columns = df.select_dtypes(include=data_types).columns\n",
    "    if ignore_target:\n",
    "        columns = filter(lambda x: x not in to_ignore, list(columns))\n",
    "    return list(columns)\n",
    "\n",
    "target = \"TARGET\"\n",
    "variables = list(get_specific_columns(df, [\"float64\", \"int64\"], [target], ignore_target = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= df_train[variables]\n",
    "y_train = df_train[target]\n",
    "\n",
    "X_test= df_test[variables]\n",
    "y_test = df_test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manoe\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0)\n",
    "fitted_model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrienving the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = fitted_model.predict(X_train)\n",
    "pred_test  = fitted_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOW CALCULATE ACCURACY SEPARATING train AND test SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy* Train: 0.9617312483116727\n",
      "Accuracy* Test: 0.9623049219687875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy* Train: {0}\".format(accuracy_score(y_train,pred_train)))\n",
    "print(\"Accuracy* Test: {0}\".format(accuracy_score(y_test,pred_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*details on appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However, as Fraud Rate is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003887432521627116\n"
     ]
    }
   ],
   "source": [
    "print(df['TARGET'].sum() / ((df['TARGET'].count()-df['TARGET'].sum())*100+df['TARGET'].sum()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A model that predicts all cases to be non-fraud has a accuracy of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996112567478372"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-df['TARGET'].sum() / ((df['TARGET'].count()-df['TARGET'].sum())*100+df['TARGET'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our model is really bad!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let´s use GINI and KS to see if there is any thing good about our model\n",
    "\n",
    "Gini & KS Statistics in Credit Scoring https://youtu.be/MiBUBVUC8kE\n",
    "\n",
    "# Things to think about during individual exercise:\n",
    "\n",
    "1. accuracy, precision, recall and f1-score vs. GINI and KS2\n",
    "1. Power vs. Robustness\r",
    "1. Linear (OLS based= vs. Non-linear (Tree based)\n",
    "1. Sample - train/test vs. cross-validation vs. Out-of-time\n",
    "1. Scaling: No Scaling vs. Standard scaling vs. Min Max Scaling\n",
    "1. Feature Selection: Bivariate, Feature Importance and Genetic Algorithm\n",
    "2. 1. Alternative Methods: Ensemble models \r",
    "\r",
    "# Confusion Matrix - Accuracy, recall & precision\n",
    "\n",
    "<img src = \"09_matriz.confusion.jpg\" width = 300 height = 300 align = \"center\">\n",
    "\n",
    "Where:\n",
    "* TP = True Positive - True Positive - It is 1 and I rate it as 1.\n",
    "* TN = True Negative - True Negative - It is 0 and I rate it as 0.\n",
    "* FN = False Negative - False Negative.\n",
    "* FP = False Positive - Positive False.\n",
    "\n",
    "\n",
    "* Accuracy (accuracy) answers the question What is the proportion of correct predictions?\n",
    "\n",
    "\\begin{equation*}\n",
    "accuracy =\n",
    "\\frac{( TP + TN )} {Total ( TP + TN + FP + FN)}\n",
    "\\end{equation*}\n",
    "\n",
    "* Sensitivity (recall) or Percent Support (support) answers the question What proportion of real positives have been correctly predicted?\n",
    "\\begin{equation*}\n",
    "recall =\n",
    "\\frac{( TP )} {( TP + FN)}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\n",
    "* Precision (Confidence) responds to the question What proportion of my positive predictions is correct?\n",
    "\\begin{equation*}\n",
    "precision =\n",
    "\\frac{( TP )} {( TP + FP)}\n",
    "\\end{equation*}\n",
    "\n",
    "Note that sensitivity and accuracy are defined here as proportion of real positives and proportion of positive predictions.\n",
    "\n",
    "#### F1-score\n",
    "\n",
    "The F1-score is a classifying metric that calculates a mean of accuracy and recall in a way that emphasizes the lowest value.\n",
    "\n",
    "It is calculated as the harmonic average of precision and recall, where an F1-score reaches its best value at 1 (perfect accuracy and reminder) and the worst at 0.\n",
    "\n",
    "<img src=\"10_f1-score.png\" width=400 height=400 align=\"center\">\n",
    "\n",
    "#### Harmonic Average\n",
    "\n",
    "The harmonic mean is defined as the inverse of the arithmetic mean of the inverses. Because of that, the result is not sensitive to extremely large values.\n",
    "\n",
    "<img src = \"11_armonic_mean.png\" width = 400 height = 400 align = \"center\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     32062\n",
      "           1       0.47      0.11      0.18      1255\n",
      "\n",
      "    accuracy                           0.96     33317\n",
      "   macro avg       0.72      0.55      0.58     33317\n",
      "weighted avg       0.95      0.96      0.95     33317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train,pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Retrienving the probability of being fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_proba = fitted_model.predict_proba(X_train)[:,1]\n",
    "pred_test_proba  = fitted_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating GINI for train and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def calculate_gini_score(a,b):\n",
    "    \"\"\"Function that received two parameters; first: a binary variable representing 0=good and 1=bad, and then a second variable with the prediction of the first variable, the second variable can be continuous, integer or binary - continuous is better. Finally, the function returns the GINI Coefficient of the two lists.\"\"\"    \n",
    "    gini = 2*roc_auc_score(a,b)-1\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINI Score TRAIN: 0.7339094995478135\n",
      "GINI Score TEST: 0.7257859325612812\n"
     ]
    }
   ],
   "source": [
    "print(\"GINI Score TRAIN: {0}\".format(calculate_gini_score(y_train, pred_train_proba)))\n",
    "print(\"GINI Score TEST: {0}\".format(calculate_gini_score(y_test, pred_test_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31246,   816],\n",
       "       [  772,   483]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, pred_train_proba>0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"08_gini.jpg\"  width=500 height=500 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "True positive rate (cut-off 10.0%): 0.0192394273193865\n",
      "1 - False Positive Rate (cut-off 10.0%): 0.9537473361947354\n",
      "----\n",
      "True positive rate (cut-off 20.0%): 0.01449710358075457\n",
      "1 - False Positive Rate (cut-off 20.0%): 0.9755079989194705\n",
      "----\n",
      "True positive rate (cut-off 30.0%): 0.010865324008764294\n",
      "1 - False Positive Rate (cut-off 30.0%): 0.984632469910256\n",
      "----\n",
      "True positive rate (cut-off 40.0%): 0.0077738091664915805\n",
      "1 - False Positive Rate (cut-off 40.0%): 0.9900051025002251\n",
      "----\n",
      "True positive rate (cut-off 50.0%): 0.004202059008914368\n",
      "1 - False Positive Rate (cut-off 50.0%): 0.995197646846955\n",
      "----\n",
      "True positive rate (cut-off 60.0%): 0.0017408530179788095\n",
      "1 - False Positive Rate (cut-off 60.0%): 0.998079058738782\n",
      "----\n",
      "True positive rate (cut-off 70.0%): 0.0007203529729567488\n",
      "1 - False Positive Rate (cut-off 70.0%): 0.9991896029054237\n",
      "----\n",
      "True positive rate (cut-off 80.0%): 0.0001200588288261248\n",
      "1 - False Positive Rate (cut-off 80.0%): 0.9997898970495542\n",
      "----\n",
      "True positive rate (cut-off 90.0%): 0.0\n",
      "1 - False Positive Rate (cut-off 90.0%): 1.0\n",
      "----\n",
      "True positive rate (cut-off 100.0%): 0.0\n",
      "1 - False Positive Rate (cut-off 100.0%): 1.0\n"
     ]
    }
   ],
   "source": [
    "for numb in range(1,11):\n",
    "    cutoff = numb/10.0\n",
    "    cm = confusion_matrix(y_train, pred_train_proba>cutoff)\n",
    "    print(\"----\")\n",
    "    print(\"True positive rate (cut-off {}%):\".format(100*cutoff),cm[1,1]/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1]))\n",
    "    print(\"1 - False Positive Rate (cut-off {}%):\".format(100*cutoff),1 - cm[0,1]/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating KS for train and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ks(b,a):  \n",
    "    \"\"\"Function that received two parameters; first: a binary variable representing 0=good and 1=bad, and then a second variable with the prediction of the first variable, the second variable can be continuous, integer or binary - continuous is better. Finally, the function returns the KS Statistics of the two lists.\"\"\"\n",
    "    try:\n",
    "        tot_bads=1.0*sum(b)\n",
    "        tot_goods=1.0*(len(b)-tot_bads)\n",
    "        elements = zip(*[a,b])\n",
    "        elements = sorted(elements,key= lambda x: x[0])\n",
    "        elements_df = pd.DataFrame({'probability': b,'gbi': a})\n",
    "        pivot_elements_df = pd.pivot_table(elements_df, values='probability', index=['gbi'], aggfunc=[sum,len]).fillna(0)\n",
    "        max_ks = perc_goods = perc_bads = cum_perc_bads = cum_perc_goods = 0\n",
    "        for i in range(len(pivot_elements_df)):\n",
    "            perc_goods =  (pivot_elements_df.iloc[i]['len'] - pivot_elements_df.iloc[i]['sum']) / tot_goods\n",
    "            perc_bads = pivot_elements_df.iloc[i]['sum']/ tot_bads\n",
    "            cum_perc_goods += perc_goods\n",
    "            cum_perc_bads += perc_bads\n",
    "            A = cum_perc_bads-cum_perc_goods\n",
    "            if abs(A['probability']) > max_ks:\n",
    "                max_ks = abs(A['probability'])\n",
    "    except:\n",
    "        max_ks = 0\n",
    "    return max_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manoe\\AppData\\Local\\Temp\\ipykernel_23452\\979497643.py:9: FutureWarning: The provided callable <built-in function sum> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot_elements_df = pd.pivot_table(elements_df, values='probability', index=['gbi'], aggfunc=[sum,len]).fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS Score TRAIN: 0.5850019670554478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manoe\\AppData\\Local\\Temp\\ipykernel_23452\\979497643.py:9: FutureWarning: The provided callable <built-in function sum> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  pivot_elements_df = pd.pivot_table(elements_df, values='probability', index=['gbi'], aggfunc=[sum,len]).fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS Score TEST: 0.5976940076330244\n"
     ]
    }
   ],
   "source": [
    "print(\"KS Score TRAIN: {0}\".format(calculate_ks(y_train, pred_train_proba)))\n",
    "print(\"KS Score TEST: {0}\".format(calculate_ks(y_test, pred_test_proba)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the cut-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"07_cost_of_fraud.JPG\"  width=500 height=500 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$PSI = \\sum{}\\Big(\\big(Actual \\% - Expected \\%\\big) \\times ln\\big(\\dfrac{Actual \\%}{Expected \\%}\\big)\\Big)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'profmanoelgadi_support_package'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprofmanoelgadi_support_package\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PSI\n\u001b[0;32m      2\u001b[0m PSI\u001b[38;5;241m.\u001b[39mcalculate_psi(X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerchant_category_code_cat\u001b[39m\u001b[38;5;124m'\u001b[39m], X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerchant_category_code_cat\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m      3\u001b[0m                   buckettype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbins\u001b[39m\u001b[38;5;124m'\u001b[39m, number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'profmanoelgadi_support_package'"
     ]
    }
   ],
   "source": [
    "from profmanoelgadi_support_package import PSI\n",
    "PSI.calculate_psi(X_train['merchant_category_code_cat'], X_test['merchant_category_code_cat'], \n",
    "                  buckettype='bins', number=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the PSI into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats=pd.DataFrame(X_train.columns,columns=['variable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSI_list = []\n",
    "for item in X_train.columns:\n",
    "    PSI_list.append(PSI.calculate_psi(X_train[item], X_test[item], buckettype='bins', number=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats['PSI']=PSI_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Value*\n",
    "\n",
    "*details on appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profmanoelgadi_support_package import IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_iv, IV = IV.data_vars(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV_list = []\n",
    "for item in X_train.columns:\n",
    "    IV_list.append(float(IV[IV['VAR_NAME']==item]['IV']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats['IV']=IV_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spearman Correlation from Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "spearmanr(X_train['merchant_category_code_cat'],X_train['merchant_category_code_previoustransaction_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(X_train['merchant_category_code_cat'],X_train['merchant_category_code_previoustransaction_cat'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in X_train.columns:\n",
    "    Spearman_correlation_list = []\n",
    "    for item2 in X_train.columns:\n",
    "        Spearman_correlation_list.append(spearmanr(X_train[item], X_train[item2])[0])\n",
    "    df_stats['corr_with_'+item]=Spearman_correlation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.sort_values(by=['PSI'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_stats.sort_values(by=['IV'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Discussions ...\n",
    "\n",
    "## Feature selection\n",
    "\n",
    "1. How can we use the PSI, IV and Correlation for Feature Selection?\n",
    "1. What else can we use for feature selection?\n",
    "\n",
    "\n",
    "## Overfitting\n",
    "\n",
    "1. What is overfitting? \n",
    "1. How to identify it? \n",
    "1. How to reduce it? \n",
    "\n",
    "\n",
    "# Things to think about during individual exercise:\n",
    "\n",
    "1. accuracy, precision, recall and f1-score vs. GINI and KS2\n",
    "1. Power vs. Robustness\n",
    "1. Linear (OLS based= vs. Non-linear (Tree based)\n",
    "1. Sample - train/test vs. cross-validation vs. Out-of-time\n",
    "1. Scaling: No Scaling vs. Standard scaling vs. Min Max Scaling\n",
    "1. Feature Selection: Bivariate, Feature Importance and Genetic Algorithm\n",
    "2. 1. Alternative Methods: Ensemble models \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
